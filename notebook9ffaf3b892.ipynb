{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8745464,"sourceType":"datasetVersion","datasetId":5251419}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install transformers[torch]\n!pip install accelerate -U\n\n# Restart your kernel after running the above commands\n\nimport urllib.request\nimport zipfile\nimport os\nfrom pathlib import Path\nimport pandas as pd\n\nurl = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\nzip_path = \"sms_spam_collection.zip\"\nextracted_path = \"sms_spam_collection\"\ndata_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n\ndef download_and_unzip(url, zip_path, extracted_path, data_file_path):\n    if data_file_path.exists():\n        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n        return\n\n    # Downloading the file\n    with urllib.request.urlopen(url) as response:\n        with open(zip_path, \"wb\") as out_file:\n            out_file.write(response.read())\n\n    # Unzipping the file\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n        zip_ref.extractall(extracted_path)\n\n    # Add .tsv file extension\n    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n    os.rename(original_file_path, data_file_path)\n    print(f\"File downloaded and saved as {data_file_path}\")\n\ndownload_and_unzip(url, zip_path, extracted_path, data_file_path)\n\ndf = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\ndf[\"Label\"] = df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\ndf.rename(columns={'Text':'Scammer'},inplace=True)\n\n\ndef create_balanced_dataset(df):\n    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n    return balanced_df\n\n\n\nbalanced_df = create_balanced_dataset(df)\nprint(balanced_df[\"Label\"].value_counts())\n\nbalanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n\n# Assuming the ScamDataNew.csv and scams13.xlsx files are already in place\ndata = pd.read_csv('/kaggle/input/scam-dataset/ScamDataNew.csv')\ntestData = pd.read_excel('/kaggle/input/scam-dataset/scams13.xlsx')\n\n# For demonstration purposes, I'll create dummy data to replace the above two dataset\n\n\ntestData.rename(columns={'content': 'Scammer'}, inplace=True)\ntestData.rename(columns={'is scam': 'Label'}, inplace=True)\nbalanced_df= pd.concat([balanced_df, data], ignore_index=True)\nbalanced_df= pd.concat([balanced_df, testData], ignore_index=True)\n\ndef random_split(df, train_frac, validation_frac):\n    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n    train_end = int(len(df) * train_frac)\n    validation_end = train_end + int(len(df) * validation_frac)\n    train_df = df[:train_end]\n    validation_df = df[train_end:validation_end]\n    test_df = df[validation_end:]\n    return train_df, validation_df, test_df\n\ntrain_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n\ntrain_df.to_csv(\"train.csv\", index=None)\nvalidation_df.to_csv(\"validation.csv\", index=None)\ntest_df.to_csv(\"test.csv\", index=None)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yRaqTvgVz-Z","outputId":"df466d7e-7002-43f7-f034-e45457f715e7","execution":{"iopub.status.busy":"2024-06-27T09:43:54.327016Z","iopub.execute_input":"2024-06-27T09:43:54.327428Z","iopub.status.idle":"2024-06-27T09:44:24.705221Z","shell.execute_reply.started":"2024-06-27T09:43:54.327392Z","shell.execute_reply":"2024-06-27T09:44:24.704229Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.30.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\nCollecting accelerate\n  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\nSuccessfully installed accelerate-0.31.0\nFile downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\nSeries([], Name: count, dtype: int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"k6d55xyhY_HZ","outputId":"894048a6-7d34-473b-d72f-e1a02c904355","execution":{"iopub.status.busy":"2024-06-27T09:44:24.707291Z","iopub.execute_input":"2024-06-27T09:44:24.707710Z","iopub.status.idle":"2024-06-27T09:44:24.727178Z","shell.execute_reply.started":"2024-06-27T09:44:24.707678Z","shell.execute_reply":"2024-06-27T09:44:24.726171Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"      Label                                            Scammer scam type  \\\n0         0  Automatic payment of Rs.3000 will be deducted ...       NaN   \n1         1  Hi there, I'm reaching out from HDFC's custome...       NaN   \n2         1  Urgent! Your PayPa1 account has been temporarl...  Phishing   \n3         0  Nitesh, 3 days for our Merry Xmas Party with P...       NaN   \n4         1  Hello, I've been trying to send the amount for...       NaN   \n...     ...                                                ...       ...   \n1287      0  Alert: We've detected unusual activity on your...  Phishing   \n1288      1  Dear Valued Customer, This is Officier John fr...  Phishing   \n1289      0  FLAT 50% OFF on purchase of 25K at the Benetto...       NaN   \n1290      1  Good day Sir. With our FAMILYSAFE plan your fa...       NaN   \n1291      0  URGENT: We've detected unusual activity on you...  Phishing   \n\n                                      trick type  \\\n0                                            NaN   \n1                                            NaN   \n2          Scarcity, Using Manipulative Language   \n3                                            NaN   \n4                                            NaN   \n...                                          ...   \n1287             Authority, Making False Threats   \n1288  Scarcity, Using Fake Accents or Identities   \n1289                                         NaN   \n1290                                         NaN   \n1291      Scarcity, Using Misleading Information   \n\n                                          attack type  \\\n0                                                 NaN   \n1                                                 NaN   \n2     Intentional spelling mistakes, Homograph Attack   \n3                                                 NaN   \n4                                                 NaN   \n...                                               ...   \n1287  Intentional spelling mistakes, Homograph Attack   \n1288  Intentional spelling mistakes, Homograph Attack   \n1289                                              NaN   \n1290                                              NaN   \n1291                    Intentional spelling mistakes   \n\n                                                 reason  \n0                                                   NaN  \n1                                                   NaN  \n2     [\"Creates a sense of urgency with 'Urgent!' to...  \n3                                                   NaN  \n4                                                   NaN  \n...                                                 ...  \n1287  [\"It's from a trusted source (the account prov...  \n1288  ['Uses scarcity tactic to create a sense of ur...  \n1289                                                NaN  \n1290                                                NaN  \n1291  ['It does not ask for sensitive information', ...  \n\n[1292 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Scammer</th>\n      <th>scam type</th>\n      <th>trick type</th>\n      <th>attack type</th>\n      <th>reason</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Automatic payment of Rs.3000 will be deducted ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Hi there, I'm reaching out from HDFC's custome...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Urgent! Your PayPa1 account has been temporarl...</td>\n      <td>Phishing</td>\n      <td>Scarcity, Using Manipulative Language</td>\n      <td>Intentional spelling mistakes, Homograph Attack</td>\n      <td>[\"Creates a sense of urgency with 'Urgent!' to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Nitesh, 3 days for our Merry Xmas Party with P...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hello, I've been trying to send the amount for...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1287</th>\n      <td>0</td>\n      <td>Alert: We've detected unusual activity on your...</td>\n      <td>Phishing</td>\n      <td>Authority, Making False Threats</td>\n      <td>Intentional spelling mistakes, Homograph Attack</td>\n      <td>[\"It's from a trusted source (the account prov...</td>\n    </tr>\n    <tr>\n      <th>1288</th>\n      <td>1</td>\n      <td>Dear Valued Customer, This is Officier John fr...</td>\n      <td>Phishing</td>\n      <td>Scarcity, Using Fake Accents or Identities</td>\n      <td>Intentional spelling mistakes, Homograph Attack</td>\n      <td>['Uses scarcity tactic to create a sense of ur...</td>\n    </tr>\n    <tr>\n      <th>1289</th>\n      <td>0</td>\n      <td>FLAT 50% OFF on purchase of 25K at the Benetto...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1290</th>\n      <td>1</td>\n      <td>Good day Sir. With our FAMILYSAFE plan your fa...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1291</th>\n      <td>0</td>\n      <td>URGENT: We've detected unusual activity on you...</td>\n      <td>Phishing</td>\n      <td>Scarcity, Using Misleading Information</td>\n      <td>Intentional spelling mistakes</td>\n      <td>['It does not ask for sensitive information', ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1292 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\nimport torch\nfrom torch.utils.data import Dataset\nimport pandas as pd\n\n\n# Add a padding token to the GPT-2 tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\nclass SpamDataset(Dataset):\n    def __init__(self, csv_file, tokenizer, max_length=None):\n        self.data = pd.read_csv(csv_file)\n        print(f\"Loaded data from {csv_file}:\")\n        print(self.data.head())  # Print the first few rows for debugging\n\n        self.tokenizer = tokenizer\n        self.max_length = max_length or 250\n        self.encoded_texts = self.tokenizer(\n            self.data[\"Scammer\"].tolist(),\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n        print(f\"Tokenization successful for {csv_file}. Sample encoding:\")\n        print(self.encoded_texts)\n\n    def __getitem__(self, index):\n        item = {key: val[index] for key, val in self.encoded_texts.items()}\n        item['labels'] = torch.tensor(self.data.iloc[index][\"Label\"], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.data)\n\n# Load datasets\nprint(\"Loading training dataset...\")\ntrain_dataset = SpamDataset('/kaggle/working/train.csv', tokenizer)\n\nprint(\"Loading validation dataset...\")\nvalidation_dataset = SpamDataset('/kaggle/working/validation.csv', tokenizer)\n\n# Model setup\nmodel = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=2)\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=5,\n    learning_rate=2e-3,\n    weight_decay=0.01,\n    per_device_train_batch_size=8,\n    evaluation_strategy=\"epoch\",\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\n# Create a data collator\ndata_collator = DataCollatorWithPadding(tokenizer)\n\n# Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    data_collator=data_collator,\n)\n\n# Train the model\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ly7cXJOZa-Pv","outputId":"83c0a479-651b-4b8e-d1a4-8da4f1b93071","execution":{"iopub.status.busy":"2024-06-27T09:44:24.728583Z","iopub.execute_input":"2024-06-27T09:44:24.729142Z","iopub.status.idle":"2024-06-27T09:50:16.989710Z","shell.execute_reply.started":"2024-06-27T09:44:24.729096Z","shell.execute_reply":"2024-06-27T09:50:16.988539Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-27 09:44:37.743026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-27 09:44:37.743154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-27 09:44:38.023802: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7d23456ed0d43bd93b4f1c3148844a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05eef4a75584be68a309c88a5c1205e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9d085a10f540dc9e26dad379387877"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23770844186744128621e134727b2b52"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c9a81cd9bb4dea953ce750a87bdcb3"}},"metadata":{}},{"name":"stdout","text":"Loading training dataset...\nLoaded data from /kaggle/working/train.csv:\n   Label                                            Scammer scam type  \\\n0      0  Automatic payment of Rs.3000 will be deducted ...       NaN   \n1      1  Hi there, I'm reaching out from HDFC's custome...       NaN   \n2      1  Urgent! Your PayPa1 account has been temporarl...  Phishing   \n3      0  Nitesh, 3 days for our Merry Xmas Party with P...       NaN   \n4      1  Hello, I've been trying to send the amount for...       NaN   \n\n                              trick type  \\\n0                                    NaN   \n1                                    NaN   \n2  Scarcity, Using Manipulative Language   \n3                                    NaN   \n4                                    NaN   \n\n                                       attack type  \\\n0                                              NaN   \n1                                              NaN   \n2  Intentional spelling mistakes, Homograph Attack   \n3                                              NaN   \n4                                              NaN   \n\n                                              reason  \n0                                                NaN  \n1                                                NaN  \n2  [\"Creates a sense of urgency with 'Urgent!' to...  \n3                                                NaN  \n4                                                NaN  \nTokenization successful for /kaggle/working/train.csv. Sample encoding:\n{'input_ids': tensor([[16541, 13730,  6074,  ..., 50256, 50256, 50256],\n        [17250,   612,    11,  ..., 50256, 50256, 50256],\n        [16692,  6783,     0,  ..., 50256, 50256, 50256],\n        ...,\n        [ 3697,  1404,  2026,  ..., 50256, 50256, 50256],\n        [10248,  1110,  7361,  ..., 50256, 50256, 50256],\n        [ 4261,    38,  3525,  ..., 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])}\nLoading validation dataset...\nLoaded data from /kaggle/working/validation.csv:\n   Label                                            Scammer scam type  \\\n0      0  URGENT: We've detected unusual activity on you...  Phishing   \n1      0  Important: This is a message from the Federal ...  Phishing   \n2      0  Hi, We are happy to inform that services for y...       NaN   \n3      0  URGENT: We've noticed unusual activity on your...  Phishing   \n4      0  ALERT! Your Airtel Black bill of Rs 316.01 for...       NaN   \n\n                                          trick type  \\\n0      Authority, Creating a Sense of False Scarcity   \n1  Authority, Using Pre-Recorded Messages to Soun...   \n2                                                NaN   \n3                      Scarcity, Playing on Emotions   \n4                                                NaN   \n\n                                       attack type  \\\n0  Homograph Attack, Intentional spelling mistakes   \n1                                 Homograph Attack   \n2                                              NaN   \n3  Intentional spelling mistakes, Homograph Attack   \n4                                              NaN   \n\n                                              reason  \n0  ['The message does not ask for sensitive infor...  \n1  ['It does not create a sense of urgency to pro...  \n2                                                NaN  \n3  [\"It's from a legitimate source (PayPal)\", 'Th...  \n4                                                NaN  \nTokenization successful for /kaggle/working/validation.csv. Sample encoding:\n{'input_ids': tensor([[ 4261,    38,  3525,  ..., 50256, 50256, 50256],\n        [33796,    25,   770,  ..., 50256, 50256, 50256],\n        [17250,    11,   775,  ..., 50256, 50256, 50256],\n        ...,\n        [   38, 46648,    11,  ..., 50256, 50256, 50256],\n        [15496,   314,  1101,  ..., 50256, 50256, 50256],\n        [11929,  8476,    25,  ..., 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4367e884f24bbfa005c9eb8e452aa0"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ·····················································································································································································································································································································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 309\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240627_094617-jvyp2dks</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/qweryuiop/huggingface/runs/jvyp2dks' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/qweryuiop/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/qweryuiop/huggingface' target=\"_blank\">https://wandb.ai/qweryuiop/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/qweryuiop/huggingface/runs/jvyp2dks' target=\"_blank\">https://wandb.ai/qweryuiop/huggingface/runs/jvyp2dks</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [405/405 03:38, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229520</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.067336</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.078781</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.148165</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.112105</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=405, training_loss=0.17226213996793016, metrics={'train_runtime': 316.0174, 'train_samples_per_second': 20.442, 'train_steps_per_second': 1.282, 'total_flos': 824207523840000.0, 'train_loss': 0.17226213996793016, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.bin')","metadata":{"id":"0Pkl5wnkbse_","execution":{"iopub.status.busy":"2024-06-27T09:53:43.202762Z","iopub.execute_input":"2024-06-27T09:53:43.203140Z","iopub.status.idle":"2024-06-27T09:53:44.333416Z","shell.execute_reply.started":"2024-06-27T09:53:43.203087Z","shell.execute_reply":"2024-06-27T09:53:44.332022Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n\n# Export the model to ONNX format\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\ndummy_input = torch.randint(0, 50257, size=(1, 250), dtype=torch.long,device=device)\ntorch.onnx.export(model, dummy_input, 'model.safetensors', export_params=True, opset_version=12)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:59:02.942782Z","iopub.execute_input":"2024-06-27T09:59:02.943489Z","iopub.status.idle":"2024-06-27T09:59:10.710776Z","shell.execute_reply.started":"2024-06-27T09:59:02.943454Z","shell.execute_reply":"2024-06-27T09:59:10.709730Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:5857: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"dummy_input","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:53:45.982766Z","iopub.execute_input":"2024-06-27T09:53:45.983045Z","iopub.status.idle":"2024-06-27T09:53:45.995059Z","shell.execute_reply.started":"2024-06-27T09:53:45.983021Z","shell.execute_reply":"2024-06-27T09:53:45.994055Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"tensor([[ 2.3372e-01,  1.4083e+00, -2.0686e+00,  8.6857e-01, -8.0322e-01,\n         -1.1209e+00,  1.9564e-01, -7.8152e-01, -6.1194e-01,  6.0262e-01,\n         -8.3618e-01, -3.3326e-01, -4.8010e-01, -1.2872e+00,  7.3888e-01,\n          3.3895e-02, -1.1860e+00,  1.2986e+00,  8.9667e-01, -2.1818e+00,\n          6.1277e-02,  8.5261e-02,  7.4813e-01, -1.6356e-01,  3.0481e-01,\n          5.1303e-01, -1.2514e+00, -8.3081e-01,  4.9816e-01, -1.2000e+00,\n          1.2711e-01,  4.4037e-01,  4.7277e-01,  3.6402e-01, -2.8120e-01,\n         -1.0375e+00, -1.8737e+00,  2.3259e+00, -9.2039e-01,  6.6611e-01,\n          8.9822e-01, -1.5388e-01, -5.6820e-01, -8.6795e-02, -8.4834e-01,\n          1.6489e+00,  1.6006e+00, -7.8589e-02,  9.7003e-01, -6.7577e-01,\n          2.0425e-01, -2.6476e-02, -4.1379e-01,  5.1841e-01, -7.0154e-01,\n         -4.3234e-01,  6.6608e-02, -9.1199e-01,  3.6821e-01,  7.0497e-01,\n         -1.0838e+00, -3.8893e-01,  8.1261e-01,  1.4981e+00,  3.1258e-01,\n         -5.2286e-02, -1.8611e-01, -7.8841e-01, -1.2787e+00, -3.8427e-02,\n          1.9138e+00,  3.3784e-01,  2.0705e-02,  7.4287e-01, -3.0620e-01,\n          5.9373e-01,  4.5572e-01,  2.5033e-01, -1.3611e+00,  1.8018e+00,\n          1.5287e+00, -9.3240e-01,  1.3527e+00,  1.6028e-01, -4.1456e-01,\n         -6.9024e-01, -2.2996e-01, -2.1723e+00,  1.6077e+00, -8.0643e-01,\n          7.3201e-02, -2.0952e+00, -9.5362e-01, -9.2473e-02, -1.0167e+00,\n         -7.6757e-03, -1.3237e+00, -3.6746e-01,  1.0117e+00, -1.4080e+00,\n          2.1296e+00, -1.5181e+00,  1.3873e-01, -1.1798e+00,  1.1162e+00,\n          2.9159e-01,  2.9770e-01,  7.5923e-01, -2.7936e+00, -7.1115e-01,\n          5.2352e-01, -1.7106e+00, -7.8717e-01,  2.4992e+00, -3.0195e-01,\n          2.2069e-01,  1.5133e-01,  7.3939e-01,  2.7310e-01,  2.7312e+00,\n         -4.5870e-01, -1.5441e-01, -2.1314e-01, -8.8802e-01, -1.0874e-01,\n         -4.1890e-01,  1.4384e+00, -7.0684e-01,  1.6513e+00, -5.1567e-01,\n         -7.5318e-01, -5.5455e-02,  3.2203e-01,  4.4606e-01,  1.5230e+00,\n          1.2805e+00,  7.2196e-01, -5.9426e-01,  1.9674e-01, -4.0626e-01,\n         -1.3642e+00,  8.2057e-03, -4.0586e-01, -7.1109e-01, -5.9511e-01,\n         -1.4568e-01, -3.8542e-01,  8.1006e-01,  9.5949e-01,  1.0351e-01,\n          8.2903e-01,  2.0921e+00,  1.4306e+00, -2.5830e-01, -7.9175e-01,\n          4.7021e-01,  9.0639e-02,  1.7423e+00, -1.2660e+00,  3.8916e-01,\n          1.1128e-01, -1.5339e+00, -8.7439e-01,  2.1726e+00,  2.2524e-01,\n         -7.7245e-02,  9.8569e-01,  1.2783e+00, -3.4867e-01, -8.2238e-01,\n         -1.4740e+00, -3.5021e-01,  4.5902e-01,  5.3093e-01, -1.3615e+00,\n          1.9562e+00, -7.1250e-01, -1.5326e-01,  8.2447e-01,  1.4659e+00,\n         -1.0087e-03, -8.4943e-01, -1.6594e+00,  3.0629e-01, -1.7602e-02,\n         -1.9953e+00,  1.2103e+00, -1.3310e-01,  8.2437e-01,  7.9835e-01,\n          1.8890e+00,  5.9346e-01,  4.1699e-02, -3.3566e-01, -1.2594e+00,\n         -2.1307e-01,  3.4436e-01, -3.1016e+00, -1.4587e+00, -1.4318e+00,\n          1.3071e-01,  1.7127e+00,  6.4644e-01,  1.3794e-01,  5.2335e-01,\n         -8.2118e-01, -4.7087e-01,  6.0164e-01,  3.5015e-02,  8.4218e-01,\n         -2.1079e-01,  8.0115e-01,  1.6917e-02,  8.0277e-02,  7.4484e-01,\n          1.3455e+00,  1.2975e+00, -9.6455e-02,  1.3945e+00, -1.3005e+00,\n         -7.3467e-01,  4.4657e-02, -1.5211e+00,  3.4784e-01, -3.9783e-01,\n          7.5833e-01, -5.3466e-01, -1.4576e-01,  9.2130e-01,  5.2824e-01,\n         -8.2284e-03, -1.4493e+00,  5.8851e-01,  7.0912e-01,  2.2405e-01,\n         -7.5548e-01,  8.6708e-01,  1.9191e-01,  1.1600e+00, -8.8152e-03,\n          8.5048e-01, -8.4964e-01, -6.6041e-01,  1.1353e-01,  3.5569e-01,\n          1.2056e+00,  1.3690e+00, -6.9496e-01,  1.4324e+00,  2.2762e-01]])"},"metadata":{}}]},{"cell_type":"code","source":"from google.colab import drive","metadata":{"execution":{"iopub.status.busy":"2024-06-27T10:02:48.113562Z","iopub.execute_input":"2024-06-27T10:02:48.114303Z","iopub.status.idle":"2024-06-27T10:02:48.162820Z","shell.execute_reply.started":"2024-06-27T10:02:48.114271Z","shell.execute_reply":"2024-06-27T10:02:48.161410Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"],"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}